
module: TrainerModule

dataset: 
  path: sst2
  split: 
    train: train[:5%]
    valid: test[:5%]

batches_per_epoch: 10

# submodules: 
#   algocean: get_cfg(ocean.module)
pipeline: 
  module: transformers.DistilBertTokenizer
  init:
    fn: from_pretrained 
    kwargs:
      pretrained_model_name_or_path: 'distilbert-base-uncased'
  params: 
    # return_tensors: pt
    padding: True
    truncation: True
    max_length: 10

  features: 
    meta: ['idx']
    remove: ['sentence']
    map: 
      label: labels
    
  format: torch


metric: 'accuracy'
epochs: 1
batch_size: 8

schedular:
  module: transformers.get_scheduler
  params:
    name: linear
    num_warmup_steps: 0

optimizer: 
  module: torch.optim.AdamW
  params:
    lr: 0.00005
scheduler: {}
model: 
  module: transformers.DistilBertForSequenceClassification
  init:
    fn: from_pretrained 
    kwargs:
      pretrained_model_name_or_path: distilbert-base-uncased
      ignore_mismatched_sizes: True

  params:
    padding: max_length
    truncation: True 



client: {}